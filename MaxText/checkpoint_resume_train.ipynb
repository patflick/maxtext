{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16e892f7-e326-4e62-baf9-25a63fc38c9b",
   "metadata": {},
   "source": [
    "# MaxText Lingvo continued training\n",
    "\n",
    "Loads a pre-existing checkpoint of the converged LG dummy model (single\n",
    "attention layer), and then runs some additional training steps (fine-tuning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd639915-a6b8-4c14-a3e6-27ef0dd5935b",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a434f0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('run_name', 'finetuning-dummy_v1'),\n",
       "             ('load_parameters_path', ''),\n",
       "             ('load_from_other_directory',\n",
       "              'gs://mazumdera-test-bucket/maxtext/lg/11032023/1/1xv3-8/checkpoints/'),\n",
       "             ('load_from_other_directory_step', 85),\n",
       "             ('reuse_example_batch', 0),\n",
       "             ('metrics_file', ''),\n",
       "             ('gcs_metrics', False),\n",
       "             ('dtype', dtype(bfloat16)),\n",
       "             ('int8_training', False),\n",
       "             ('global_parameter_scale', 1),\n",
       "             ('base_emb_dim', 512),\n",
       "             ('base_num_heads', 4),\n",
       "             ('base_mlp_dim', 2048),\n",
       "             ('base_num_decoder_layers', 1),\n",
       "             ('head_dim', 96),\n",
       "             ('mlp_activations', ['gelu']),\n",
       "             ('dropout_rate', 0),\n",
       "             ('logits_via_embedding', True),\n",
       "             ('remat_policy', 'full'),\n",
       "             ('scan_layers', True),\n",
       "             ('param_scan_axis', 1),\n",
       "             ('enable_flash_attention', False),\n",
       "             ('record_internal_nn_metrics', 0),\n",
       "             ('base_output_directory',\n",
       "              'gs://patflick-maxtext-lingvo/maxtext/dummy/20231120'),\n",
       "             ('mesh_axes', ['data', 'fsdp', 'tensor']),\n",
       "             ('logical_axis_rules',\n",
       "              (('activation_batch', ('data', 'fsdp')),\n",
       "               ('activation_length', ('data', 'fsdp')),\n",
       "               ('activation_embed', 'tensor'),\n",
       "               ('activation_mlp', 'tensor'),\n",
       "               ('activation_heads', 'tensor'),\n",
       "               ('activation_kv', 'tensor'),\n",
       "               ('activation_vocab', 'tensor'),\n",
       "               ('mlp', 'tensor'),\n",
       "               ('vocab', 'tensor'),\n",
       "               ('embed', 'fsdp'),\n",
       "               ('heads', 'tensor'))),\n",
       "             ('data_sharding', (('data', 'fsdp', 'tensor'),)),\n",
       "             ('dcn_data_parallelism', -1),\n",
       "             ('dcn_fsdp_parallelism', 1),\n",
       "             ('dcn_tensor_parallelism', 1),\n",
       "             ('ici_data_parallelism', 1),\n",
       "             ('ici_fsdp_parallelism', -1),\n",
       "             ('ici_tensor_parallelism', 4),\n",
       "             ('dataset_path', ''),\n",
       "             ('vocab_size', 50272),\n",
       "             ('assets_path', 'assets'),\n",
       "             ('vocab_relative_path', 'tokenizer'),\n",
       "             ('dataset_name', 'c4/en:3.0.1'),\n",
       "             ('eval_dataset_name', 'c4/en:3.0.1'),\n",
       "             ('eval_split', 'validation'),\n",
       "             ('per_device_batch_size', 0.5),\n",
       "             ('eval_per_device_batch_size', 0),\n",
       "             ('max_corpus_chars', 10000000),\n",
       "             ('dataset_type', 'lg'),\n",
       "             ('file_pattern_for_train_data',\n",
       "              'gs://yejingxin-us-central2/external/lg/dummy-data/train/*.tfrecords'),\n",
       "             ('file_pattern_for_eval_data',\n",
       "              'gs://yejingxin-us-central2/external/lg/dummy-data/valid/*tfrecords'),\n",
       "             ('steps', 1000),\n",
       "             ('log_period', 100),\n",
       "             ('save_period', 100),\n",
       "             ('learning_rate', 3e-05),\n",
       "             ('cosine_learning_rate_final_fraction', 0.1),\n",
       "             ('warmup_steps_fraction', 0.1),\n",
       "             ('learning_rate_schedule_steps', 1000),\n",
       "             ('max_target_length', 2048),\n",
       "             ('max_eval_target_length', 512),\n",
       "             ('max_predict_length', 64),\n",
       "             ('sampling_temperature', 0.6),\n",
       "             ('sampling_top_k', 20),\n",
       "             ('eos_id', 2),\n",
       "             ('prompt', 'I love to '),\n",
       "             ('enable_profiler', False),\n",
       "             ('enable_checkpointing', True),\n",
       "             ('async_checkpointing', True),\n",
       "             ('enable_dropout', True),\n",
       "             ('enable_data_shuffling', True),\n",
       "             ('data_shuffle_seed', 0),\n",
       "             ('init_weights_seed', 0),\n",
       "             ('gradient_clipping_threshold', 1.0),\n",
       "             ('adam_b1', 0.9),\n",
       "             ('adam_b2', 0.95),\n",
       "             ('adam_eps', 1e-08),\n",
       "             ('adam_eps_root', 0.0),\n",
       "             ('adam_weight_decay', 0.1),\n",
       "             ('collect_stack_trace', False),\n",
       "             ('stack_trace_to_cloud', False),\n",
       "             ('stack_trace_interval_seconds', 600),\n",
       "             ('use_iota_embed', False),\n",
       "             ('tensorboard_dir',\n",
       "              'gs://patflick-maxtext-lingvo/maxtext/dummy/20231120/finetuning-dummy_v1/tensorboard/'),\n",
       "             ('checkpoint_dir',\n",
       "              'gs://patflick-maxtext-lingvo/maxtext/dummy/20231120/finetuning-dummy_v1/checkpoints/'),\n",
       "             ('metrics_dir',\n",
       "              'gs://patflick-maxtext-lingvo/maxtext/dummy/20231120/finetuning-dummy_v1/metrics/'),\n",
       "             ('emb_dim', 512),\n",
       "             ('num_heads', 4),\n",
       "             ('mlp_dim', 2048),\n",
       "             ('num_decoder_layers', 1),\n",
       "             ('global_batch_size_to_load', 4),\n",
       "             ('global_batch_size_to_train_on', 2)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_bucket = \"gs://patflick-maxtext-lingvo\"\n",
    "base_output_directory= my_bucket + \"/maxtext/dummy/20231120\"\n",
    "\n",
    "# Path to converted checkpoints\n",
    "checkpoint_path = \"gs://mazumdera-test-bucket/maxtext/lg/11032023/1/1xv3-8/checkpoints/\"\n",
    "\n",
    "# Adapt config to our model\n",
    "extra_config = {\n",
    "    # Run config\n",
    "    \"run_name\": \"finetuning-dummy_v2\",\n",
    "    \"base_output_directory\": base_output_directory,\n",
    "    \"save_period\": 100,\n",
    "    \"steps\": 1000,\n",
    "\n",
    "    # Load checkpoint\n",
    "    \"load_from_other_directory\": checkpoint_path,\n",
    "    \"load_from_other_directory_step\": 85,\n",
    "\n",
    "    # Model config (this has to match the loaded checkpoint, otherwise ERROR!)\n",
    "    \"base_num_decoder_layers\": 1,\n",
    "    \"base_num_heads\": 4,\n",
    "    \"head_dim\": 96,\n",
    "    \"vocab_size\": 50272,\n",
    "    \"per_device_batch_size\": 0.5,\n",
    "    \"base_mlp_dim\": 2048,\n",
    "    \"base_emb_dim\": 512,\n",
    "\n",
    "    # Dataset loader to use\n",
    "    \"dataset_type\": \"lg\",\n",
    "    \"file_pattern_for_train_data\": \"gs://yejingxin-us-central2/external/lg/dummy-data/train/*.tfrecords\",\n",
    "    \"file_pattern_for_eval_data\": \"gs://yejingxin-us-central2/external/lg/dummy-data/valid/*tfrecords\",\n",
    "\n",
    "    # Parallelism and KV config\n",
    "    \"dcn_tensor_parallelism\": 1,\n",
    "    \"ici_tensor_parallelism\": 4,\n",
    "    \"enable_flash_attention\": False,\n",
    "}\n",
    "\n",
    "import pyconfig\n",
    "pyconfig.initialize([\"\", \"configs/base.yml\"] + [f\"{k}={v}\" for k,v in extra_config.items()])\n",
    "config = pyconfig.config\n",
    "pyconfig._config.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72f70461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating checkpoint manager...\n",
      "Checkpoint manager created!\n",
      "Devices: [TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0), TpuDevice(id=1, process_index=0, coords=(1,0,0), core_on_chip=0), TpuDevice(id=2, process_index=0, coords=(0,1,0), core_on_chip=0), TpuDevice(id=3, process_index=0, coords=(1,1,0), core_on_chip=0)] (num_devices: 4)\n",
      "Decided on mesh: [[[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0)\n",
      "   TpuDevice(id=2, process_index=0, coords=(0,1,0), core_on_chip=0)\n",
      "   TpuDevice(id=1, process_index=0, coords=(1,0,0), core_on_chip=0)\n",
      "   TpuDevice(id=3, process_index=0, coords=(1,1,0), core_on_chip=0)]]]\n",
      "Trying to read training data from path: gs://yejingxin-us-central2/external/lg/dummy-data/train/*.tfrecords\n",
      "Training dataset has: 500000 entries\n",
      "Trying to read eval data from path: gs://yejingxin-us-central2/external/lg/dummy-data/valid/*tfrecords\n",
      "Eval dataset has: 50000 entries\n",
      "restoring state from this run's directory latest step         900\n",
      "number parameters: 0.029 billion\n",
      "Per train step, total TFLOPs will be 0.19, split as 94.79% learnable weight flops and 5.21% attention flops\n",
      "completed step: 901, seconds: 3.079, TFLOP/s: 0.060, loss: 11.240\n",
      "completed step: 902, seconds: 0.271, TFLOP/s: 0.684, loss: 11.236\n",
      "completed step: 903, seconds: 0.012, TFLOP/s: 15.194, loss: 11.241\n",
      "completed step: 904, seconds: 0.012, TFLOP/s: 15.256, loss: 11.235\n",
      "completed step: 905, seconds: 0.012, TFLOP/s: 15.545, loss: 11.255\n",
      "completed step: 906, seconds: 0.012, TFLOP/s: 15.814, loss: 11.226\n",
      "completed step: 907, seconds: 0.012, TFLOP/s: 15.712, loss: 11.247\n",
      "completed step: 908, seconds: 0.012, TFLOP/s: 15.848, loss: 11.241\n",
      "completed step: 909, seconds: 0.012, TFLOP/s: 15.302, loss: 11.245\n",
      "completed step: 910, seconds: 0.012, TFLOP/s: 15.637, loss: 11.239\n",
      "completed step: 911, seconds: 0.012, TFLOP/s: 14.893, loss: 11.273\n",
      "completed step: 912, seconds: 0.012, TFLOP/s: 15.366, loss: 11.248\n",
      "completed step: 913, seconds: 0.012, TFLOP/s: 15.599, loss: 11.222\n",
      "completed step: 914, seconds: 0.012, TFLOP/s: 15.531, loss: 11.274\n",
      "completed step: 915, seconds: 0.012, TFLOP/s: 15.261, loss: 11.247\n",
      "completed step: 916, seconds: 0.012, TFLOP/s: 15.253, loss: 11.248\n",
      "completed step: 917, seconds: 0.012, TFLOP/s: 15.492, loss: 11.244\n",
      "completed step: 918, seconds: 0.012, TFLOP/s: 15.791, loss: 11.244\n",
      "completed step: 919, seconds: 0.012, TFLOP/s: 15.687, loss: 11.262\n",
      "completed step: 920, seconds: 0.012, TFLOP/s: 15.809, loss: 11.260\n",
      "completed step: 921, seconds: 0.012, TFLOP/s: 15.661, loss: 11.241\n",
      "completed step: 922, seconds: 0.012, TFLOP/s: 15.894, loss: 11.237\n",
      "completed step: 923, seconds: 0.012, TFLOP/s: 15.598, loss: 11.237\n",
      "completed step: 924, seconds: 0.012, TFLOP/s: 15.294, loss: 11.235\n",
      "completed step: 925, seconds: 0.012, TFLOP/s: 15.526, loss: 11.226\n",
      "completed step: 926, seconds: 0.012, TFLOP/s: 15.797, loss: 11.234\n",
      "completed step: 927, seconds: 0.012, TFLOP/s: 16.073, loss: 11.250\n",
      "completed step: 928, seconds: 0.012, TFLOP/s: 15.603, loss: 11.248\n",
      "completed step: 929, seconds: 0.012, TFLOP/s: 15.437, loss: 11.244\n",
      "completed step: 930, seconds: 0.012, TFLOP/s: 15.848, loss: 11.252\n",
      "completed step: 931, seconds: 0.012, TFLOP/s: 16.025, loss: 11.258\n",
      "completed step: 932, seconds: 0.012, TFLOP/s: 15.455, loss: 11.235\n",
      "completed step: 933, seconds: 0.012, TFLOP/s: 16.012, loss: 11.255\n",
      "completed step: 934, seconds: 0.012, TFLOP/s: 15.591, loss: 11.250\n",
      "completed step: 935, seconds: 0.012, TFLOP/s: 15.429, loss: 11.260\n",
      "completed step: 936, seconds: 0.012, TFLOP/s: 15.487, loss: 11.273\n",
      "completed step: 937, seconds: 0.012, TFLOP/s: 15.879, loss: 11.249\n",
      "completed step: 938, seconds: 0.012, TFLOP/s: 15.690, loss: 11.261\n",
      "completed step: 939, seconds: 0.012, TFLOP/s: 15.967, loss: 11.247\n",
      "completed step: 940, seconds: 0.012, TFLOP/s: 15.488, loss: 11.242\n",
      "completed step: 941, seconds: 0.012, TFLOP/s: 15.722, loss: 11.230\n",
      "completed step: 942, seconds: 0.012, TFLOP/s: 15.985, loss: 11.262\n",
      "completed step: 943, seconds: 0.012, TFLOP/s: 15.540, loss: 11.241\n",
      "completed step: 944, seconds: 0.012, TFLOP/s: 15.828, loss: 11.229\n",
      "completed step: 945, seconds: 0.012, TFLOP/s: 15.528, loss: 11.236\n",
      "completed step: 946, seconds: 0.011, TFLOP/s: 16.194, loss: 11.247\n",
      "completed step: 947, seconds: 0.012, TFLOP/s: 15.722, loss: 11.224\n",
      "completed step: 948, seconds: 0.011, TFLOP/s: 16.164, loss: 11.232\n",
      "completed step: 949, seconds: 0.012, TFLOP/s: 16.083, loss: 11.225\n",
      "completed step: 950, seconds: 0.012, TFLOP/s: 15.333, loss: 11.249\n",
      "completed step: 951, seconds: 0.012, TFLOP/s: 15.722, loss: 11.257\n",
      "completed step: 952, seconds: 0.012, TFLOP/s: 15.695, loss: 11.232\n",
      "completed step: 953, seconds: 0.012, TFLOP/s: 15.584, loss: 11.253\n",
      "completed step: 954, seconds: 0.012, TFLOP/s: 15.738, loss: 11.212\n",
      "completed step: 955, seconds: 0.012, TFLOP/s: 15.667, loss: 11.244\n",
      "completed step: 956, seconds: 0.012, TFLOP/s: 15.694, loss: 11.233\n",
      "completed step: 957, seconds: 0.011, TFLOP/s: 16.146, loss: 11.248\n",
      "completed step: 958, seconds: 0.012, TFLOP/s: 15.550, loss: 11.242\n",
      "completed step: 959, seconds: 0.012, TFLOP/s: 15.989, loss: 11.236\n",
      "completed step: 960, seconds: 0.012, TFLOP/s: 15.957, loss: 11.256\n",
      "completed step: 961, seconds: 0.012, TFLOP/s: 16.093, loss: 11.253\n",
      "completed step: 962, seconds: 0.012, TFLOP/s: 16.129, loss: 11.244\n",
      "completed step: 963, seconds: 0.011, TFLOP/s: 16.187, loss: 11.247\n",
      "completed step: 964, seconds: 0.012, TFLOP/s: 16.084, loss: 11.261\n",
      "completed step: 965, seconds: 0.012, TFLOP/s: 16.050, loss: 11.244\n",
      "completed step: 966, seconds: 0.012, TFLOP/s: 15.969, loss: 11.246\n",
      "completed step: 967, seconds: 0.012, TFLOP/s: 15.755, loss: 11.246\n",
      "completed step: 968, seconds: 0.012, TFLOP/s: 15.983, loss: 11.230\n",
      "completed step: 969, seconds: 0.012, TFLOP/s: 15.732, loss: 11.254\n",
      "completed step: 970, seconds: 0.012, TFLOP/s: 15.778, loss: 11.234\n",
      "completed step: 971, seconds: 0.012, TFLOP/s: 15.876, loss: 11.250\n",
      "completed step: 972, seconds: 0.012, TFLOP/s: 15.782, loss: 11.252\n",
      "completed step: 973, seconds: 0.012, TFLOP/s: 15.477, loss: 11.228\n",
      "completed step: 974, seconds: 0.012, TFLOP/s: 15.180, loss: 11.258\n",
      "completed step: 975, seconds: 0.012, TFLOP/s: 15.484, loss: 11.263\n",
      "completed step: 976, seconds: 0.012, TFLOP/s: 16.066, loss: 11.261\n",
      "completed step: 977, seconds: 0.012, TFLOP/s: 15.996, loss: 11.278\n",
      "completed step: 978, seconds: 0.012, TFLOP/s: 16.083, loss: 11.249\n",
      "completed step: 979, seconds: 0.012, TFLOP/s: 15.782, loss: 11.263\n",
      "completed step: 980, seconds: 0.012, TFLOP/s: 15.786, loss: 11.236\n",
      "completed step: 981, seconds: 0.012, TFLOP/s: 15.818, loss: 11.253\n",
      "completed step: 982, seconds: 0.012, TFLOP/s: 15.387, loss: 11.255\n",
      "completed step: 983, seconds: 0.012, TFLOP/s: 15.679, loss: 11.241\n",
      "completed step: 984, seconds: 0.012, TFLOP/s: 15.190, loss: 11.261\n",
      "completed step: 985, seconds: 0.012, TFLOP/s: 15.649, loss: 11.263\n",
      "completed step: 986, seconds: 0.012, TFLOP/s: 15.669, loss: 11.219\n",
      "completed step: 987, seconds: 0.012, TFLOP/s: 16.022, loss: 11.217\n",
      "completed step: 988, seconds: 0.012, TFLOP/s: 15.322, loss: 11.241\n",
      "completed step: 989, seconds: 0.012, TFLOP/s: 15.857, loss: 11.232\n",
      "completed step: 990, seconds: 0.012, TFLOP/s: 15.224, loss: 11.240\n",
      "completed step: 991, seconds: 0.012, TFLOP/s: 15.475, loss: 11.236\n",
      "completed step: 992, seconds: 0.012, TFLOP/s: 15.407, loss: 11.244\n",
      "completed step: 993, seconds: 0.012, TFLOP/s: 15.518, loss: 11.255\n",
      "completed step: 994, seconds: 0.012, TFLOP/s: 15.693, loss: 11.249\n",
      "completed step: 995, seconds: 0.012, TFLOP/s: 15.847, loss: 11.260\n",
      "completed step: 996, seconds: 0.012, TFLOP/s: 15.368, loss: 11.263\n",
      "completed step: 997, seconds: 0.012, TFLOP/s: 15.893, loss: 11.255\n",
      "completed step: 998, seconds: 0.012, TFLOP/s: 15.882, loss: 11.236\n",
      "completed step: 999, seconds: 0.012, TFLOP/s: 15.592, loss: 11.237\n"
     ]
    }
   ],
   "source": [
    "import train\n",
    "import jax\n",
    "\n",
    "train.train_loop(config) \n",
    "jax.distributed.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
